{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fashion_mnist",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOivO/EOuS+XzNPJVmGudiw"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygE5eb8g3IHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "e1143c54-6820-4b90-96a2-f0177940d94f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import IPython\n",
        "from tensorflow import keras\n",
        "import kerastuner as kt\n",
        "import datetime\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_images = train_images.astype('float64') / 255.0\n",
        "\n",
        "test_images = test_images.astype('float64') / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(60000).batch(64)\n",
        "test_dataset = test_dataset.batch(64)\n",
        "\n",
        "def model_builder(hp):\n",
        "    global model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    global hp_units\n",
        "    hp_units = hp.Int('units', min_value=2, max_value=99999, step=32)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "\n",
        "    f = hp.Choice('False', 'True')\n",
        "\n",
        "    global hp_dropout\n",
        "\n",
        "    hp_dropout = 0\n",
        "\n",
        "    if f == 'False':\n",
        "      hp_dropout = hp.Choice('dropout', values=(0.1, 0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9))\n",
        "    if f == 'True':\n",
        "      hp_dropout = 0\n",
        "      \n",
        "    model.add(keras.layers.Dropout(hp_dropout))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    global hp_learning_rate\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=(1e-5, 1e-4, 1e-6, 1e-7, 1e-1, 1e-2, 1e-3, 1e-4))\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='Fashion_mnist_KT_logs')\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "    def on_train_end(*args, **kwargs):\n",
        "        IPython.display.clear_output(wait=True)\n",
        "\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n",
        "\n",
        "tuner.search(train_images, train_labels, epochs=15, validation_data=(test_images, test_labels),\n",
        "             callbacks=[ClearTrainingOutput()])\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyper-parameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}\n",
        "\"\"\")\n",
        "\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/fit/' + current_time + '/train'\n",
        "test_log_dir = 'logs/fit/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "logdir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, verbose=0,\n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "model.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n",
        "\n",
        "def run(run_dir, hp):\n",
        "    with tf.summary.create_file_writer(run_dir).as_default():\n",
        "        hp.hparams(hp)  # record the values used in this trial\n",
        "        accuracy = model_builder(hp)\n",
        "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "\n",
        "def train_step(model, optimizer, train_images, train_labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(train_images, training=True)\n",
        "        loss = loss_object(train_labels, predictions)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(train_labels, predictions)\n",
        "\n",
        "\n",
        "def test_step(model, test_images, test_labels):\n",
        "    predictions = model(test_images)\n",
        "    loss = loss_object(test_labels, predictions)\n",
        "\n",
        "    test_loss(loss)\n",
        "    test_accuracy(test_labels, predictions)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "\n",
        "for epoch in range(15):\n",
        "    for (train_images, train_labels) in train_dataset:\n",
        "        train_step(model, optimizer, train_images, train_labels)\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "\n",
        "    for (test_images, test_labels) in test_dataset:\n",
        "        test_step(model, test_images, test_labels)\n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])\n",
        "\n",
        "predictions = probability_model.predict(test_images)\n",
        "\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    true_label, img = true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100 * np.max(predictions_array),\n",
        "                                         class_names[true_label]),\n",
        "               color=color)\n",
        "\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    true_label = true_label[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks(range(10))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')\n",
        "\n",
        "\n",
        "num_rows = 3\n",
        "num_cols = 9\n",
        "num_images = num_rows * num_cols\n",
        "plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
        "    plot_image(i, predictions[i], test_labels, test_images)\n",
        "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
        "    plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project my_dir/Fashion_mnist_KT_logs/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from my_dir/Fashion_mnist_KT_logs/tuner0.json\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyper-parameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 66 and the optimal learning rate for the optimizer\n",
            "is 0.1\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (32, 28, 2)               58        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (32, 28, 2)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (32, 28, 10)              30        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (32, 280)                 0         \n",
            "=================================================================\n",
            "Total params: 88\n",
            "Trainable params: 0\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n",
            "313/313 - 1s - loss: 5.6346 - accuracy: 0.0073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7d219a24716a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtest_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7d219a24716a>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(model, test_images, test_labels)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAN8kUyUmOrK",
        "outputId": "1a5e3592-39e9-45f0-d3c2-cd8f9f813e99"
      },
      "source": [
        "pip -q install keras-tuner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 33.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 38.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 26.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 24.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}